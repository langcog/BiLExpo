---
title: "Initial Analysis of Wordbank Data"
author: "George, Alvin, Julien, ..."
format: html
editor: source
---

# Setup
```{r}
knitr::opts_chunk$set(message = FALSE)
```

```{r, message=F}
library(tidyverse)
library(here)
library(glue)
library(wordbankr)
library(gamlss)
library(lmtest)
library(lmerTest)
library(qqplotr)
library(doParallel)

theme_set(theme_classic())
walk(list.files("scripts", full.names = TRUE), source)
```

# Vocabulary models
## Get data 
Get all datasets explicitly labelled "bilingual"
```{r, cache=T}
bilingual_datasets <- get_datasets() |> 
  filter(str_detect(dataset_origin_name, "Bilingual"))
```

Wrangle exposure data
```{r, cache=T}
bilingual_data <- get_administration_data(include_demographic_info = TRUE,
                                          include_language_exposure = TRUE) |> 
  filter(dataset_origin_name %in% bilingual_datasets$dataset_origin_name) |>
  unnest(language_exposures, names_sep = "_") |>
  filter(!is.na(language_exposures_language),
         !is.na(language_exposures_exposure_proportion)) |>
  rename(exposure_language = language_exposures_language,
         exposure_proportion = language_exposures_exposure_proportion,
         age_first_exposed = language_exposures_age_of_first_exposure) |>
  select(-c(age_first_exposed, is_norming, date_of_test)) |> 
  filter(str_detect(language, glue("^{exposure_language}")))

# The Armon-Lotem data only have 4 values for exposure_proportion
bilingual_data_clean <- bilingual_data |> 
  filter(dataset_origin_name != "Armon-Lotem_Hebrew_English_Bilingual")
```

## Preprocess data
```{r}
all_instruments <- bilingual_data_clean |> 
  distinct(language, form)
```

Find number of items on each form
```{r}
items <- map2(all_instruments$language, all_instruments$form, get_item_data) |> 
  list_rbind() |> 
  group_by(language, form) |> 
  filter(item_kind == "word") |> 
  summarise(n = n(), .groups = "drop")

bilingual_data_prop <- bilingual_data_clean |> 
  left_join(items, by = join_by(language, form)) |> 
  mutate(prop_prod = production / n,
         prop_prod = case_when(
           prop_prod == 0 ~ .001,
           prop_prod == 1 ~ .999,
           .default = prop_prod
         ),
         child_id = as_factor(child_id))
```

View all data
```{r}
bilingual_data_prop |>
  ggplot(aes(x = age, y=production, color=language)) +
  geom_point(alpha=.2) + 
  geom_smooth()
```

Filter down to just Eng (Am) data for now
```{r}
bilingual_data_prop_en <- bilingual_data_prop |> 
  filter(language == "English (American)")
```

## Nonlinear model
Fit GAMLSS model with monotonic spline for exposure
```{r, message=F}
data_mod <- bilingual_data_prop_en |> 
                          select(prop_prod, age, exposure_proportion, child_id)

gam_nonlinear <- gamlss(prop_prod ~ pbm(age, lambda = 10000) * 
                          pbm(exposure_proportion, lambda = 10000) +
                          re(random = ~ 1 | child_id, level = 0),
                        sigma.formula = ~ pbm(age, lambda = 10000) * 
                          pbm(exposure_proportion, lambda = 10000),
                        data = data_mod,
                        family = BE,
                        control = gamlss.control(n.cyc = 100))

# model checking:
# look at outliers in q-q plot
# some structure in fitted value resid plot?
# 
# can try fitting for each lang separately and check the curve shape (robustness checking)
```

Plot model predictions 
```{r}
plot_preds(gam_nonlinear)
```

```{r}
plot_preds(gam_nonlinear, x = "age")
```

### Diagnostics
```{r}
plot(gam_nonlinear)
```

The default plots are not great; we manually plot some diagnostics of interest using ggplot

Quantile residuals against fitted values. Some structure; this is corroborated in the wormplot.
```{r}
plot_resids(gam_nonlinear)
```

Q-Q plot
```{r}
plot_qq(gam_nonlinear)
```

Worm plot (detrended qq-plot)
```{r}
plot_wp(gam_nonlinear)
```

Trying to diagnose structure in residuals
```{r}
gam_nl_moddata <- plot_resids(gam_nonlinear, type = "df")
ggplot(gam_nl_moddata,
       aes(x = age, y = resid)) +
  geom_hline(yintercept = 0, lty = "dashed") +
  geom_point(alpha = .5) +
  geom_smooth()
```

```{r}
ggplot(gam_nl_moddata,
       aes(x = exposure_proportion, y = resid)) +
  geom_hline(yintercept = 0, lty = "dashed") +
  geom_point(alpha = .5) +
  geom_smooth()
```

### Partial effect plot
```{r}
plot_partial(gam_nonlinear)
plot_partial(gam_nonlinear, x = "age")
```

## Fiddling with lambda
### Fitting lambda
```{r}
gam_nonlinear_lmb <- gamlss(prop_prod ~ pbm(age, 
                                            control = pbm.control(method = "GCV")) * 
                              pbm(exposure_proportion, 
                                  control = pbm.control(method = "GCV")) +
                              re(random = ~ 1 | child_id, level = 0),
                            sigma.formula = ~ pbm(age, 
                                                  control = pbm.control(method = "GCV")) *  
                              pbm(exposure_proportion, 
                                  control = pbm.control(method = "GCV")),
                            data = data_mod,
                            family = BE,
                            control = gamlss.control(n.cyc = 100))
```

Extract lambda values
```{r}
gam_nl_lmb <- tibble(
  param = rep(c("mu", "sigma"), each = 2),
  term = rep(c(1, 2), 2)
) |> 
  mutate(lambda = map2_dbl(param, term, \(p, t) getSmo(gam_nonlinear_lmb, p, which = t)$lambda),
         term = factor(term, levels = c(1, 2), labels = c("age", "exposure_proportion")))
```

```{r}
lrtest(gam_nonlinear, gam_nonlinear_lmb)
```

### Lower lambda model
```{r}
gam_nonlinear_low <- gamlss(prop_prod ~ pbm(age, lambda = 10) * 
                              pbm(exposure_proportion, lambda = 10) +
                              re(random = ~ 1 | child_id, level = 0),
                            sigma.formula = ~ pbm(age, lambda = 10) *  
                              pbm(exposure_proportion, lambda = 10),
                            data = data_mod,
                            family = BE,
                            control = gamlss.control(n.cyc = 250))
```

### Even lower lambda model
```{r eval=F}
gam_nonlinear_lower <- gamlss(prop_prod ~ pbm(age, lambda = 1) * 
                              pbm(exposure_proportion, lambda = 1) +
                              re(random = ~ 1 | child_id, level = 0),
                            sigma.formula = ~ pbm(age, lambda = 1) *  
                              pbm(exposure_proportion, lambda = 1),
                            data = data_mod,
                            family = BE,
                            control = gamlss.control(n.cyc = 250))
```

```{r}
plot_partial(gam_nonlinear_lower)
```

## ZOIB model?
```{r}
data_zoib <- data_mod |> 
  mutate(prop_prod = case_when(
    prop_prod == .001 ~ 0,
    prop_prod == .999 ~ 1,
    .default = prop_prod
  ))
gam_nonlinear_zoib <- gamlss(prop_prod ~ pbm(age, lambda = 10000) * 
                               pbm(exposure_proportion, lambda = 10000) +
                               re(random = ~ 1 | child_id, level = 0),
                             sigma.formula = ~ pbm(age, lambda = 10000) * 
                               pbm(exposure_proportion, lambda = 10000),
                             data = data_zoib,
                             family = BEINF,
                             control = gamlss.control(n.cyc = 100))
```

```{r}
plot_preds(gam_nonlinear_zoib)
```

```{r}
plot_preds(gam_nonlinear_zoib, x = "age")
```

```{r}
plot_partial(gam_nonlinear_zoib)
```


## Linear model
Compare with linear exposure term
```{r}
gam_linear <- gamlss(prop_prod ~ pbm(age, lambda = 10000) * 
                       exposure_proportion +
                       re(random = ~ 1 | child_id, level = 0),
                     sigma.formula = ~ pbm(age, lambda = 10000) * 
                       exposure_proportion,
                     data = bilingual_data_prop_en |> 
                       select(prop_prod, age, exposure_proportion, child_id),
                     family = BE,
                     control = gamlss.control(n.cyc = 100))

# try nonlinear in mu, linear in sigma
# or nonlinear in mu, NOT in sigma etc.

lrtest(gam_linear, gam_nonlinear)
```
The model with a nonlinear exposure term is significantly better than the model with a linear exposure term (using a likelihood ratio test). (This result also holds if you use AIC for model selection, but there is no significant difference using BIC.)

Now fitting on data from all current languages
```{r}
data_plotting <- bilingual_data_prop |> 
  select(prop_prod, age, exposure_proportion, 
         child_id, language)

gam_nonlinear_all <- gamlss(prop_prod ~ pbm(age, lambda = 10000) * 
                              pbm(exposure_proportion, lambda = 10000) +
                              re(random = ~ 1 | child_id, level = 0) +
                              re(random = ~ 1 | language, level = 0),
                            sigma.formula = ~ pbm(age, lambda = 10000) * 
                              pbm(exposure_proportion, lambda = 10000),
                            data = data_plotting,
                            family = BE,
                            control = gamlss.control(n.cyc = 100))
gam_linear_all <- gamlss(prop_prod ~ pbm(age, lambda = 10000) * 
                           exposure_proportion +
                           re(random = ~ 1 | child_id, level = 0) +
                           re(random = ~ 1 | language, level = 0),
                         sigma.formula = ~ pbm(age, lambda = 10000) * 
                           exposure_proportion,
                         data = data_plotting,
                         family = BE,
                         control = gamlss.control(n.cyc = 100))

lrtest(gam_linear_all, gam_nonlinear_all)
```

## Expanding to Spanish
```{r}
data_spa <- bilingual_data_prop |> 
  filter(language == "Spanish (Mexican)") |> 
  select(prop_prod, age, exposure_proportion, child_id)
```

```{r}
gam_nonlinear_spa <- gamlss(prop_prod ~ pbm(age, lambda = 10000) * 
                              pbm(exposure_proportion, lambda = 10000) +
                              re(random = ~ 1 | child_id, level = 0),
                            sigma.formula = ~ pbm(age, lambda = 10000) * 
                              pbm(exposure_proportion, lambda = 10000),
                            data = data_spa,
                            family = BE,
                            control = gamlss.control(n.cyc = 100))
```

```{r}
gam_nonlinear_spa_pe <- estimate_partials(gam_nonlinear_spa, term = "exposure_proportion")
gam_nonlinear_eng_pe <- estimate_partials(gam_nonlinear, term = "exposure_proportion")
```

### Permutation testing
Are the shapes of the splines different? We permute the labels at each value of `exposure_proportion` to determine whether the correlation between curves (discretised with dx = 1) is significantly greater than would be expected by chance.

```{r}
gam_nonlinear_pe <- bind_rows(
  gam_nonlinear_spa_pe |> mutate(language = "Spanish"),
  gam_nonlinear_eng_pe |> mutate(language = "English")
)

obs_cor <- gam_nonlinear_pe |> 
  pivot_wider(names_from = language, values_from = part_exp) |> 
  summarise(cor = cor(Spanish, English))
```

```{r}
NBOOT = 1000

perm_cor <- map(1:NBOOT, \(i) {
  gam_nonlinear_pe_perm <- gam_nonlinear_pe |> 
    group_by(exposure_proportion) |> 
    mutate(language = sample(language),
           iter = i)
}) |> list_rbind() |> 
  pivot_wider(names_from = language, values_from = part_exp) |> 
  group_by(iter) |> 
  summarise(cor = cor(Spanish, English),
            .groups = "drop")
```

```{r}
p_cor <- sum(obs_cor$cor <= perm_cor$cor) / NBOOT
```

The splines are statistically different from permutation testing (observed correlation is greater than would be expected under the null distribution.)

## Cross-validation
To determine the exact form of the model, we conduct 10-fold cross-validation with RMSE as the goodness-of-fit metric.

```{r}
set.seed(42)
K = 10

data_cv <- data_mod |> 
  mutate(fold = sample(1:K, length(prop_prod), replace = TRUE))

## using the in-built gamlssCV doesn't work unfortunately… not sure why
# cv_mods <- gamlssCV(prop_prod ~ pbm(age, lambda = 10 ^ lmb) *
#                     pbm(exposure_proportion, lambda = 10 ^ lmb) +
#                     re(random = ~ 1 | child_id, level = 0),
#                   sigma.formula = ~ pbm(age, lambda = 10 ^ lmb) *  
#                     pbm(exposure_proportion, lambda = 10 ^ lmb),
#                   data = data_mod,
#                   family = BE,
#                   control = gamlss.control(n.cyc = 100),
#                   K.fold = K)


cv_mods <- map(1:K, \(k) {
  # horrendous global assigns, but for some reason gamlss is unable to find 
  # function-scoped data DFs
  data_train <<- data_cv |> filter(fold != k)
  data_val <<- data_cv |> filter(fold == k)
  
  map(2:5, \(lmb) {
    print(glue("k: {k}; lmb: {lmb}"))
    tryCatch({
      mod <- gamlss(prop_prod ~ pbm(age, lambda = 10 ^ lmb) *
                      pbm(exposure_proportion, lambda = 10 ^ lmb) +
                      re(random = ~ 1 | child_id, level = 0),
                    sigma.formula = ~ pbm(age, lambda = 10 ^ lmb) *  
                      pbm(exposure_proportion, lambda = 10 ^ lmb),
                    data = data_train,
                    family = BE,
                    control = gamlss.control(n.cyc = 100),
                    trace = FALSE)
      data_out <- data_val |> 
        mutate(preds = predict(mod,
                               newdata = data_val,
                               type = "response"))
      rmse <- data_out |> 
        mutate(err = preds - prop_prod,
               sq_err = err ^ 2) |> 
        summarise(rmse = sqrt(mean(sq_err, na.rm = TRUE))) |> 
        pull(rmse)
      
      rm(mod)
      
      tibble(lambda = 10 ^ lmb,
             preds = list(data_out),
             rmse = rmse)
    }, 
    error = \(cond) {
      tibble(lambda = 10 ^ lmb,
             preds = NULL,
             rmse = NA)
    })
  }) |> list_rbind() |> 
    mutate(k = k)
}) |> list_rbind()
```

```{r}
cv_lin <- map(1:K, \(k) {
  # horrendous global assigns, but for some reason gamlss is unable to find 
  # function-scoped data DFs
  data_train <<- data_cv |> filter(fold != k)
  data_val <<- data_cv |> filter(fold == k)
  
  mod <- gamlss(prop_prod ~ pbm(age, lambda = 1e4) *
                  exposure_proportion +
                  re(random = ~ 1 | child_id, level = 0),
                sigma.formula = ~ pbm(age, lambda = 1e4) *  
                  exposure_proportion,
                data = data_train,
                family = BE,
                control = gamlss.control(n.cyc = 100),
                trace = FALSE)
  
  data_out <- data_val |> 
    mutate(preds = predict(mod,
                           newdata = data_val,
                           type = "response"))
  rmse <- data_out |> 
    mutate(err = preds - prop_prod,
           sq_err = err ^ 2) |> 
    summarise(rmse = sqrt(mean(sq_err, na.rm = TRUE))) |> 
    pull(rmse)
  
  tibble(lambda = 10 ^ 8,
         preds = list(data_out),
         rmse = rmse,
         k = k)
}) |> list_rbind()
```


```{r}
ggplot(cv_mods, 
       aes(x = log(lambda, base = 10),
           y = rmse, 
           col = factor(log(lambda, base = 10)))) + 
  geom_line(aes(group = k), col = "grey", alpha = .5) +
  geom_point(alpha = .5) + 
  stat_summary(fun = mean,
               fun.min = function(x) mean(x) - sd(x), 
               fun.max = function(x) mean(x) + sd(x), 
               geom = "pointrange") +
  theme(legend.position = "none")
```

### Full grid search
```{r}
cv_full <- map(1:K, \(k) {
  # horrendous global assigns, but for some reason gamlss is unable to find 
  # function-scoped data DFs
  data_train <<- data_cv |> filter(fold != k)
  data_val <<- data_cv |> filter(fold == k)
  
  map(2:6, \(lmb_age) {
    map(2:6, \(lmb_exp) {
      print(glue("k: {k}; lmb_age: {lmb_age}; lmb_exp: {lmb_exp}"))
      tryCatch({
        if (lmb_age == 6 & lmb_exp == 6) {
          mod <- gamlss(prop_prod ~ age *
                        exposure_proportion +
                        re(random = ~ 1 | child_id, level = 0),
                      sigma.formula = ~ age *
                        exposure_proportion,
                      data = data_train,
                      family = BE,
                      control = gamlss.control(n.cyc = 100),
                      trace = FALSE)
        } else if (lmb_age == 6) {
          mod <- gamlss(prop_prod ~ age *
                        pbm(exposure_proportion, lambda = 10 ^ lmb_exp) +
                        re(random = ~ 1 | child_id, level = 0),
                      sigma.formula = ~ age *
                        pbm(exposure_proportion, lambda = 10 ^ lmb_exp),
                      data = data_train,
                      family = BE,
                      control = gamlss.control(n.cyc = 100),
                      trace = FALSE)
        } else if (lmb_exp == 6) {
          mod <- gamlss(prop_prod ~ pbm(age, lambda = 10 ^ lmb_age) *
                        exposure_proportion +
                        re(random = ~ 1 | child_id, level = 0),
                      sigma.formula = ~ pbm(age, lambda = 10 ^ lmb_age) *
                        exposure_proportion,
                      data = data_train,
                      family = BE,
                      control = gamlss.control(n.cyc = 100),
                      trace = FALSE)
        } else {
          mod <- gamlss(prop_prod ~ pbm(age, lambda = 10 ^ lmb_age) *
                        pbm(exposure_proportion, lambda = 10 ^ lmb_exp) +
                        re(random = ~ 1 | child_id, level = 0),
                      sigma.formula = ~ pbm(age, lambda = 10 ^ lmb_age) *  
                        pbm(exposure_proportion, lambda = 10 ^ lmb_exp),
                      data = data_train,
                      family = BE,
                      control = gamlss.control(n.cyc = 100),
                      trace = FALSE)
        }
        
        data_out <- data_val |> 
          mutate(preds = predict(mod,
                                 newdata = data_val,
                                 type = "response"))
        rmse <- data_out |> 
          mutate(err = preds - prop_prod,
                 sq_err = err ^ 2) |> 
          summarise(rmse = sqrt(mean(sq_err, na.rm = TRUE))) |> 
          pull(rmse)
        
        aic <- AIC(mod)
        bic <- BIC(mod)
        
        rm(mod)
        
        tibble(lambda_age = 10 ^ lmb_age,
               lambda_exp = 10 ^ lmb_exp,
               preds = list(data_out),
               rmse = rmse,
               aic = aic,
               bic = bic)
      }, 
      error = \(cond) {
        tibble(lambda_age = 10 ^ lmb_age,
               lambda_exp = 10 ^ lmb_exp,
               preds = NULL,
               rmse = NA,
               aic = NA,
               bic = NA)
      })
    }) |> list_rbind()
  }) |> list_rbind() |> 
    mutate(k = k)
}) |> list_rbind()
```

```{r}
ggplot(cv_full, 
       aes(x = log(lambda_age, base = 10),
           y = rmse, 
           col = factor(log(lambda_age, base = 10)))) + 
  geom_line(aes(group = lambda_exp), col = "grey", alpha = .5) +
  geom_point(alpha = .5) + 
  stat_summary(fun = mean,
               fun.min = function(x) mean(x) - sd(x), 
               fun.max = function(x) mean(x) + sd(x), 
               geom = "pointrange") +
  theme(legend.position = "none")
```

Brief summary of observations: there is some variance due to the age term, and almost none due to the exposure term. Split is actually a large contributor to variance.

Decision point: We base our choice for lambda on the age term on prior work (lambda = 10e4), and then do CV over the full data to determine whether the exposure term is nonlinear.

# Word-level models
## Get data
```{r, cache=T, eval=F}
bilingual_admin_data <- get_administration_data(include_demographic_info = TRUE,
                                                include_language_exposure = TRUE) |> 
  filter(dataset_origin_name %in% bilingual_datasets$dataset_origin_name)

bilingual_item_data <- map(unique(bilingual_admin_data$language), \(lang) {
  get_instrument_data(
    language = lang,
    form = "WS",
    administration_info = bilingual_admin_data,
    item_info = TRUE)
}) |> list_rbind() |> 
  filter(dataset_origin_name %in% bilingual_datasets$dataset_origin_name) |>
  unnest(language_exposures, names_sep = "_") |>
  filter(!is.na(language_exposures_language),
         !is.na(language_exposures_exposure_proportion)) |>
  rename(exposure_language = language_exposures_language,
         exposure_proportion = language_exposures_exposure_proportion,
         age_first_exposed = language_exposures_age_of_first_exposure) |>
  select(-c(age_first_exposed, is_norming, date_of_test)) |> 
  filter(str_detect(language, glue("^{exposure_language}")))

# The Armon-Lotem data only have 4 values for exposure_proportion
bilingual_item_data_clean <- bilingual_item_data |> 
  filter(dataset_origin_name != "Armon-Lotem_Hebrew_English_Bilingual")

saveRDS(bilingual_item_data_clean, "data/bilingual_item_data_clean.rds")
```

```{r}
bilingual_item_data_clean <- readRDS("data/bilingual_item_data_clean.rds")
```


## Fit model
```{r}
data_item <- bilingual_item_data_clean |> 
  filter(dataset_origin_name == "Marchman Dallas Bilingual") |> 
  select(produces, age, exposure_proportion, child_id, uni_lemma, item_id, language) |> 
  na.omit()
```

```{r eval=F}
# this model takes ages to fit and will eat your memory! 
gam_item_nonlinear <- gamlss(produces ~ age * 
                               pbm(exposure_proportion, lambda = 10000) +
                               re(random = ~ 1 | child_id, level = 0) +
                               re(random = ~ 1 | uni_lemma, level = 0) +
                               re(random = ~ 1 | item_id, level = 0) +
                               re(random = ~ 1 | language, level = 0),
                        data = data_item,
                        family = BI,
                        control = gamlss.control(n.cyc = 100))
```

## Exposure proportion models
```{r}
library(lme4)
data_item_sc <- data_item |> 
  mutate(age_sc = scale(age),
         exp_sc = scale(exposure_proportion))

glm_item_lin <- glmer(produces ~ age_sc * exp_sc +
                        (1 | child_id) + (1 | uni_lemma) + (1 | item_id) + (1 | language),
                      data = data_item_sc,
                      family = binomial)

glm_item_quad <- glmer(produces ~ age_sc * poly(exp_sc, 2) +
                         (1 | child_id) + (1 | uni_lemma) + (1 | item_id) + (1 | language),
                       data = data_item_sc,
                       family = binomial)

glm_item_log <- glmer(produces ~ age_sc * log(exposure_proportion + .5) +
                         (1 | child_id) + (1 | uni_lemma) + (1 | item_id) + (1 | language),
                       data = data_item_sc,
                       family = binomial)

glm_item_exp <- glmer(produces ~ age_sc * exp(exp_sc) +
                         (1 | child_id) + (1 | uni_lemma) + (1 | item_id) + (1 | language),
                       data = data_item_sc,
                       family = binomial)
```

Note that log causes some NaNs due to zero values. 

## Cross-validation
```{r}
set.seed(42)
K = 10

data_item_cv <- data_item_sc |> 
  mutate(fold = sample(1:K, length(produces), replace = TRUE),
         log_exp_sc = scale(log(exposure_proportion + .5)),
         across(ends_with("_sc"), c))

## using the in-built gamlssCV doesn't work unfortunately… not sure why
# cv_mods <- gamlssCV(prop_prod ~ pbm(age, lambda = 10 ^ lmb) *
#                     pbm(exposure_proportion, lambda = 10 ^ lmb) +
#                     re(random = ~ 1 | child_id, level = 0),
#                   sigma.formula = ~ pbm(age, lambda = 10 ^ lmb) *  
#                     pbm(exposure_proportion, lambda = 10 ^ lmb),
#                   data = data_mod,
#                   family = BE,
#                   control = gamlss.control(n.cyc = 100),
#                   K.fold = K)


# cv_item_mods <- map(1:K, \(k) {
cl <- makeCluster(5)
registerDoParallel(cl)
cv_item_mods <- foreach(k = 1:K,
                        .packages = c("dplyr", "purrr", "gamlss", "lme4", "glue")) %dopar% {
  data_train <- data_item_cv |> filter(fold != k)
  data_val <- data_item_cv |> filter(fold == k)
  
  map(c("linear", "quadratic", "cubic", "logarithmic", "exponential", "sigmoidal"), \(mod_type) {
    print(glue("k: {k}; mod_type: {mod_type}"))
    tryCatch({
      start_time <- Sys.time()
      if (mod_type == "linear") {
        mod <- glmer(produces ~ age_sc * exp_sc +
                       (1 | child_id) + (1 | uni_lemma) + (1 | item_id) + (1 | language),
                     data = data_train,
                     family = binomial)
      } else if (mod_type == "quadratic") {
        mod <- glmer(produces ~ age_sc * poly(exp_sc, 2) +
                       (1 | child_id) + (1 | uni_lemma) + (1 | item_id) + (1 | language),
                     data = data_train,
                     family = binomial,
                     control = glmerControl(optimizer ="bobyqa", optCtrl = list(maxfun = 2e5)))
      } else if (mod_type == "cubic") {
        mod <- glmer(produces ~ age_sc * poly(exp_sc, 3) +
                       (1 | child_id) + (1 | uni_lemma) + (1 | item_id) + (1 | language),
                     data = data_train,
                     family = binomial,
                     control = glmerControl(optimizer ="bobyqa", optCtrl = list(maxfun = 2e5)))
      } else if (mod_type == "logarithmic") {
        mod <- glmer(produces ~ age_sc * log_exp_sc +
                       (1 | child_id) + (1 | uni_lemma) + (1 | item_id) + (1 | language),
                     data = data_train,
                     family = binomial)
      } else if (mod_type == "exponential") {
        mod <- glmer(produces ~ age_sc * exp(exp_sc) +
                       (1 | child_id) + (1 | uni_lemma) + (1 | item_id) + (1 | language),
                     data = data_train,
                     family = binomial)
      } else if (mod_type == "sigmoidal") {
        mod <- glmer(produces ~ age_sc * (1 / (1 + exp(-exp_sc))) +
                       (1 | child_id) + (1 | uni_lemma) + (1 | item_id) + (1 | language),
                     data = data_train,
                     family = binomial)
      }
      end_time <- Sys.time()
      print(glue("Time elapsed: {end_time - start_time}"))
      
      data_out <- data_val |> 
        mutate(preds = predict(mod,
                               newdata = data_val,
                               type = "response"))
      rmse <- data_out |> 
        mutate(err = preds - produces,
               sq_err = err ^ 2) |> 
        summarise(rmse = sqrt(mean(sq_err, na.rm = TRUE))) |> 
        pull(rmse)
      
      rm(mod)
      
      tibble(mod_type = mod_type,
             preds = list(data_out),
             rmse = rmse)
    }, 
    error = \(cond) {
      tibble(mod_type = mod_type,
             preds = NULL,
             rmse = NA)
    })
  }) |> list_rbind() |> 
    mutate(k = k)
} |> list_rbind()

saveRDS(cv_item_mods, "models/cv_item_mods.rds")
```

```{r}
cv_item_mods <- cv_item_mods |> 
  mutate(mod_type = factor(mod_type, 
                           levels = c("linear", "quadratic", "cubic", 
                                      "logarithmic", "exponential", "sigmoidal")))

ggplot(cv_item_mods, 
       aes(x = mod_type,
           y = rmse, 
           col = factor(mod_type))) + 
  geom_point(alpha = .5) + 
  stat_summary(fun = mean,
               fun.min = function(x) mean(x) - sd(x), 
               fun.max = function(x) mean(x) + sd(x), 
               geom = "pointrange") +
  theme(legend.position = "none") +
  labs(x = "Model type",
       y = "RMSE")
```

```{r}
lmer(rmse ~ mod_type + (1 | k), 
     data = cv_item_mods |> mutate(mod_type = mod_type |> relevel("cubic"))) |>
  summary()
```


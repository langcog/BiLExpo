---
title: "Bayesian Models"
author: "George"
date: "`r Sys.Date()`"
output: html_document
header-includes: 
  - \usepackage{tikz}
  - \usepackage{pgfplots}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

require(tidyverse)
library(ggplot2)
library(bayesplot)
library(rstan)

source("scripts/stan_helpers.R")
```

## Load data

```{r load-and-prep-data, include=F}
bilingual_item_data_clean <- readRDS("data/bilingual_item_data_clean.Rds")

# below, see if different lex cats have different functional forms
# function_words          nouns          other     predicates 
#         37434         114504          36700          60922 
```


```{r}
stan_data <- prepare_stan_data(bilingual_item_data_clean, #n_items=300, # can do 300 with 64gb RAM
                               original_dataset_name = "Marchman Dallas Bilingual")
```


Let's try copying Alvin's GAMLSS model in Stan.

### Linear Exposure Model

```{r, eval=F}
rstan_options(auto_write = TRUE) 
options(mc.cores = parallel::detectCores())

fit_linear <- stan(file = "models/model2.stan",
            data = stan_data,
            model_name = "linear",
            control = list(max_treedepth=15),
            iter = 4000, warmup = 1000, chains = 4, seed = 123)
saveRDS(fit_linear, file="models/model2_fit.rds")
rm(fit_linear)
```

...by lexical category:

```{r, eval=F}
rstan_options(auto_write = TRUE) 
options(mc.cores = parallel::detectCores())

fit_stan_by_lexical_category(
  data = bilingual_item_data_clean,
  model_file = "models/model2.stan",
  model_name = "linear",
  output_dir = "models",
  original_dataset_name = "Marchman Dallas Bilingual",
  seed = 123
)
```

```{r}
fit <- readRDS("models/model2_fit_nouns.rds")
m2_nouns <- summarize_exposure_by_age(fit, plot=F)
rm(fit)
```

```{r}
fit <- readRDS("models/model2_fit_function_words.rds")
m2_function_words <- summarize_exposure_by_age(fit, plot=F)
rm(fit)
```

```{r}
fit <- readRDS("models/model2_fit_predicates.rds")
m2_predicates <- summarize_exposure_by_age(fit, plot=F)
rm(fit)
```

```{r}
fit <- readRDS("models/model2_fit_other.rds")
m2_other <- summarize_exposure_by_age(fit, plot=F)
rm(fit)
```

```{r}
m2_lex_cat <- m2_nouns |> mutate(lex_cat = "nouns") |>
  bind_rows(m2_function_words |> mutate(lex_cat = "function words")) |>
  bind_rows(m2_predicates |> mutate(lex_cat = "predicates")) |>
  bind_rows(m2_other |> mutate(lex_cat = "other"))
```

```{r}
m2_lex_cat |> ggplot(aes(x=age, y=mean, group=lex_cat)) +
  geom_line(linewidth = 1.2, aes(color=lex_cat)) +
      geom_ribbon(aes(ymin = lower, ymax = upper, fill=lex_cat), alpha = 0.2) +
      xlab("Age (years)") + ylab("Exposure Effect (posterior mean Â± 95% CI)") +
      theme_minimal(base_size = 14)
```


```{r}
results <- summarize_and_plot_by_lexcat(
  model_base = "model2_fit",
  output_dir = "models",
  exposure_param = "beta_exposure",
  item_param = "u_item"
)
```



```{r, eval=F}
rstan_options(auto_write = TRUE) 
options(mc.cores = parallel::detectCores())

fit_quad <- stan(file = "models/model5-quadratic-exposure.stan",
            data = stan_data,
            model_name = "quadratic",
            control = list(max_treedepth=12),
            iter = 4000, warmup = 1000, chains = 4, seed = 123)
saveRDS(fit_quad, file="models/model5_fit.rds")
rm(fit_quad)
```

```{r, eval=F}
rstan_options(auto_write = TRUE) 
options(mc.cores = parallel::detectCores())

fit_cubic <- stan(file = "models/model6-cubic-exposure.stan",
            data = stan_data,
            model_name = "cubic",
            control = list(max_treedepth=12),
            iter = 4000, warmup = 1000, chains = 4, seed = 123)
saveRDS(fit_cubic, file="models/model6_fit.rds")
rm(fit_cubic)
```


```{r}
# Check the results
fit_linear <- readRDS("models/model2_fit.rds")
plot(fit_linear, pars=c("beta_age", "beta_exposure", "beta_age_exposure")) # alpha
```

## Posterior Predictive Check

```{r, eval=F}
# Extract generated quantities
y_rep <- extract(fit_linear)$y_rep

# For example, compute the posterior predictive mean for each observation
y_rep_mean <- apply(y_rep, 2, mean)

# Plot observed vs. predicted probabilities (or frequencies)
df_ppc <- data.frame(
  observed = y,
  predicted = y_rep_mean
)

ggplot(df_ppc, aes(x = predicted, fill = factor(observed))) +
  geom_histogram(position = "dodge", bins = 30) +
  labs(title = "Posterior Predictive Distribution",
       x = "Predicted probability",
       fill = "Observed (0/1)") +
  theme_minimal()
```


# Model 3: Non-linear Effect of Age


```{r}
library(splines)

# Generate a B-spline basis for age with 4 degrees of freedom
age_spline <- bs(data_item$age, df = 4)

# Add the spline basis 
data_item <- cbind(data_item, age_spline)

# Prepare the Stan data list
stan_data <- list(
  N = nrow(data_item),
  I = length(unique(data_item$child_id)),
  W = length(unique(data_item$uni_lemma)),
  J = length(unique(data_item$item_id)),
  L = length(unique(data_item$language)),
  y = data_item$produces,
  exposure = data_item$exposure_proportion,
  child = as.integer(as.factor(data_item$child_id)),
  word = as.integer(as.factor(data_item$uni_lemma)),
  item = as.integer(as.factor(data_item$item_id)),
  lang = as.integer(as.factor(data_item$language)),
  age_spline = as.matrix(age_spline)  # Pass spline basis as a matrix
)
```

```{r, eval=F}
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores()) 

fit <- stan(file = "models/model3-age-spline.stan",
            data = stan_data,
            model_name = "age-spline",
            control = list(max_treedepth=12),
            iter = 2500, warmup = 1000, chains = 4, seed = 123,
            thin = 2)
saveRDS(fit, file="models/model3-age-spline_fit.rds")
```

```{r}
# Check the results
fit <- readRDS("models/model3-age-spline_fit.rds")
#plot(fit)
```

```{r}
plot(fit, pars=c("beta_age_spline[1]", "beta_age_spline[2]", 
                 "beta_age_spline[3]", "beta_age_spline[4]",
                 "beta_exposure", "beta_age_exposure"))
```

## Posterior Predictive Check


```{r}
posterior_samples <- extract(fit)
beta_age_spline <- posterior_samples$beta_age_spline

age_range <- seq(min(data_item$age), max(data_item$age), length.out = 100)

# Create the spline basis for the age range (using the same settings as in your STAN model)
age_spline_basis <- ns(age_range, df = 4)  # 4 degrees of freedom used in your STAN model

# Calculate the predicted spline for the mean of the posterior samples
mean_beta_age_spline <- colMeans(beta_age_spline)

# Generate predicted splines for each posterior sample
predicted_splines <- age_spline_basis %*% t(beta_age_spline)

# Compute the 2.5th and 97.5th percentiles for the uncertainty intervals
ci_lower <- apply(predicted_splines, 1, quantile, probs = 0.025)
ci_upper <- apply(predicted_splines, 1, quantile, probs = 0.975)

spline_df <- data.frame(age_range, predicted_spline, ci_lower, ci_upper)

# Plot with credible intervals
ggplot(spline_df, aes(x = age_range)) +
  geom_line(aes(y = predicted_spline), color = "blue", size = 1) +
  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), alpha = 0.2, fill = "blue") +
  labs(x = "Age", y = "Predicted Spline Effect", title = "Fitted Spline with 95% Credible Interval") +
  theme_minimal()
```

```{r}
plot_children(posterior_samples)
plot_items(posterior_samples)
```


```{r, eval=F}
# Extract generated quantities
y_rep <- extract(fit)$y_rep

# compute the posterior predictive mean for each observation
y_rep_mean <- apply(y_rep, 2, mean)

df_ppc <- data.frame(
  observed = stan_data$y,                # Actual outcomes (binary: word produced or not)
  predicted = y_rep_mean,                # Predicted probabilities
  child = stan_data$child,               # Child ID for each observation
  exposure = stan_data$exposure,
  age = data_item$age
)

df_ppc$residuals <- df_ppc$observed - df_ppc$predicted

df_vocab <- df_ppc %>%
  group_by(child) %>%
  summarize(
    total_observed_vocab = sum(observed),   # Total actual words produced by child
    total_predicted_vocab = sum(predicted), # Total predicted vocabulary size
    mean_age = mean(age),      # Average age per child (or replace with raw age if available)
    exposure = mean(exposure)
  )

# Residuals vs age plot
ggplot(df_ppc, aes(x = age, y = residuals)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = "loess", color = "blue", se = FALSE) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Residuals vs. Age",
    x = "Age",
    y = "Residuals (Observed - Predicted)"
  ) +
  theme_minimal()

ggplot(df_ppc, aes(x = exposure, y = residuals)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = "loess", color = "blue", se = FALSE) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Residuals vs. Exposure",
    x = "Exposure",
    y = "Residuals (Observed - Predicted)"
  ) +
  theme_minimal()
```

```{r}
# Extend df_ppc to include total observed/predicted vocab per child
df_ppc <- df_ppc %>%
  group_by(child) %>%
  mutate(
    total_observed_vocab = sum(observed),   # Total actual words produced by child
    total_predicted_vocab = sum(predicted), # Total predicted vocabulary size
    mean_age_spline = mean(age_spline)      # Average age (or use actual age if available)
  ) %>%
  ungroup()

# Posterior predictive distribution with facets for each child
ggplot(df_ppc, aes(x = predicted, fill = factor(observed))) +
  geom_histogram(position = "dodge", bins = 30) +
  facet_wrap(~ child, ncol = 5) +  # Facet by child
  labs(
    title = "Posterior Predictive Distribution by Child",
    x = "Predicted Probability",
    fill = "Observed (0/1)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


# Model 4: Non-linear Effect of Exposure

```{r}
library(splines)

# Generate a B-spline basis for exposure with 4 degrees of freedom
exposure_spline <- bs(data_item$exposure_proportion, df = 4)

# Add the spline basis 
data_item <- cbind(data_item, exposure_spline)

# Prepare the Stan data list
stan_data <- list(
  N = nrow(data_item),
  I = length(unique(data_item$child_id)),
  W = length(unique(data_item$uni_lemma)),
  J = length(unique(data_item$item_id)),
  L = length(unique(data_item$language)),
  y = data_item$produces,
  age = data_item$age,
  child = as.integer(as.factor(data_item$child_id)),
  word = as.integer(as.factor(data_item$uni_lemma)),
  item = as.integer(as.factor(data_item$item_id)),
  lang = as.integer(as.factor(data_item$language)),
  exposure_spline = as.matrix(exposure_spline)
)
```

```{r, eval=F}
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores()) 

fit <- stan(file = "models/model4-exposure-spline.stan",
            data = stan_data,
            model_name = "exposure-spline",
            control = list(max_treedepth=12),
            iter = 2500, warmup = 1000, chains = 4, seed = 123,
            thin = 2)
saveRDS(fit, file="models/model4-exposure-spline_fit.rds")
```

```{r}
# Check the results
fit <- readRDS("models/model4-exposure-spline_fit.rds")
#plot(fit)
plot(fit, pars=c("beta_exposure_spline[1]", "beta_exposure_spline[2]", 
                 "beta_exposure_spline[3]", "beta_exposure_spline[4]",
                 "beta_age", "beta_age_exposure"))
```

## Posterior Predictive Check


```{r}
posterior_samples <- extract(fit)
beta_exposure_spline <- posterior_samples$beta_exposure_spline

exposure_proportion <- seq(min(data_item$exposure_proportion), 
                 max(data_item$exposure_proportion), length.out = 100)

# Create the spline basis for the age range (using the same settings as in your STAN model)
exp_spline_basis <- ns(exposure_proportion, df = 4)  # 4 degrees of freedom 

# Calculate the predicted spline for the mean of the posterior samples
mean_beta_exp_spline <- colMeans(beta_exposure_spline)

# Generate predicted splines for each posterior sample
predicted_splines <- exp_spline_basis %*% t(beta_exposure_spline)

# Compute the 2.5th and 97.5th percentiles for the uncertainty intervals
ci_lower <- apply(predicted_splines, 1, quantile, probs = 0.025)
ci_upper <- apply(predicted_splines, 1, quantile, probs = 0.975)

spline_df <- data.frame(exposure_proportion, predicted_splines, ci_lower, ci_upper)

# Plot with credible intervals
ggplot(spline_df, aes(x = exposure_proportion)) +
  geom_line(aes(y = predicted_spline), color = "blue", size = 1) +
  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), alpha = 0.2, fill = "blue") +
  labs(x = "Exposure Proportion", y = "Predicted Spline Effect", title = "Fitted Spline with 95% Credible Interval") +
  theme_minimal()
```


### Quadratic Exposure Model


```{r}
# Check the results
fit_quad <- readRDS("models/model5_fit.rds")
plot(fit, pars=c("beta_age", "beta_exposure", "beta_exposure2", "beta_age_exposure")) # alpha
```


### Cubic Exposure Model


```{r}
# Check the results
fit_cubic <- readRDS("models/model6_fit.rds")
plot(fit_cubic, pars=c("beta_age", "beta_exposure", "beta_exposure2", "beta_exposure3", 
                 "beta_age_exposure")) # alpha
```


## Model Comparison

Lower LOOIC is better. If ÎLOOIC > ~4 and SE is small, thatâs strong evidence the lower model is better.
If differences are small or uncertain (SE > ÎLOOIC), look at even simpler models or posterior predictive checks.

```{r}
library(loo)

fit_linear <- readRDS("models/model2_fit.rds")
fit_quad <- readRDS("models/model5_fit.rds")
fit_cubic <- readRDS("models/model6_fit.rds")

# Extract log_lik matrices
log_lik_linear <- extract_log_lik(fit_linear, merge_chains = FALSE)
log_lik_quad   <- extract_log_lik(fit_quad, merge_chains = FALSE)
log_lik_cubic  <- extract_log_lik(fit_cubic, merge_chains = FALSE)

# Compute LOO for eachWarning: Can't fit generalized Pareto distribution because all tail values are the same.
loo_linear <- loo(log_lik_linear)
loo_quad   <- loo(log_lik_quad)
loo_cubic  <- loo(log_lik_cubic)

# Compare them
loo_compare(loo_linear, loo_quad, loo_cubic)
```


## Plot Exposure Effects


```{r}
# Exposure sequence
exposure_seq <- seq(0, 1, length.out = 100)

# Set age to mean or fixed value
mean_age <- mean(stan_data$age)

# Create a new data frame for prediction
new_data <- data.frame(
  age = rep(mean_age, 100),
  exposure = exposure_seq
)
```


```{r}
predict_exposure_effect <- function(fit, new_data, degree = c("linear", "quadratic", "cubic")) {
  posterior <- rstan::extract(fit)
  
  alpha <- posterior$alpha
  beta_age <- posterior$beta_age
  beta_exposure <- posterior$beta_exposure
  beta_age_exposure <- posterior$beta_age_exposure
  
  # Add higher-order terms as needed
  if ("quadratic" %in% degree) {
    beta_exposure2 <- posterior$beta_exposure2
    eta <- outer(1:nrow(new_data), 1:length(alpha), 
                 Vectorize(function(i, s) alpha[s] +
                                             beta_age[s] * new_data$age[i] +
                                             beta_exposure[s] * new_data$exposure[i] +
                                             beta_exposure2[s] * new_data$exposure[i]^2 +
                                             beta_age_exposure[s] * new_data$age[i] * new_data$exposure[i]))
  } else if ("cubic" %in% degree) {
    beta_exposure2 <- posterior$beta_exposure2
    beta_exposure3 <- posterior$beta_exposure3
    eta <- outer(1:nrow(new_data), 1:length(alpha), 
                 Vectorize(function(i, s) alpha[s] +
                                             beta_age[s] * new_data$age[i] +
                                             beta_exposure[s] * new_data$exposure[i] +
                                             beta_exposure2[s] * new_data$exposure[i]^2 +
                                             beta_exposure3[s] * new_data$exposure[i]^3 +
                                             beta_age_exposure[s] * new_data$age[i] * new_data$exposure[i]))
  } else {
    eta <- outer(1:nrow(new_data), 1:length(alpha), 
                 Vectorize(function(i, s) alpha[s] +
                                             beta_age[s] * new_data$age[i] +
                                             beta_exposure[s] * new_data$exposure[i] +
                                             beta_age_exposure[s] * new_data$age[i] * new_data$exposure[i]))
  }
  
  # Convert to predicted probabilities
  p <- plogis(eta)
  
  # Mean and 95% CI across draws
  pred_mean <- apply(p, 1, mean)
  pred_lower <- apply(p, 1, quantile, probs = 0.025)
  pred_upper <- apply(p, 1, quantile, probs = 0.975)
  
  data.frame(
    exposure = new_data$exposure,
    mean = pred_mean,
    lower = pred_lower,
    upper = pred_upper,
    model = degree
  )
}
```


```{r}
df_linear <- predict_exposure_effect(fit_linear, new_data, "linear")
df_quad   <- predict_exposure_effect(fit_quad, new_data, "quadratic")
df_cubic  <- predict_exposure_effect(fit_cubic, new_data, "cubic")

df_all <- rbind(df_linear, df_quad, df_cubic)
```


```{r}
ggplot(df_all, aes(x = exposure, y = mean, color = model, fill = model)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2, color = NA) +
  labs(
    title = "Predicted Word Production Probability by Exposure",
    x = "Exposure Proportion",
    y = "Predicted Probability",
    color = "Model",
    fill = "Model"
  ) +
  theme_minimal(base_size = 14)
```

